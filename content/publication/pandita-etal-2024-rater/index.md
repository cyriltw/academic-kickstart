---
title: Rater Cohesion and Quality from a Vicarious Perspective
featured: false
authors:
- Deepak Pandita
- Tharindu Cyril Weerasooriya
- Sujan Dutta
- Sarah K. Luger
- Tharindu Ranasinghe
- Ashiqur R. KhudaBukhsh
- Marcos Zampieri
- Christopher M. Homan
date: '2024-11-01'
publishDate: '2025-03-09T03:15:13.817681Z'
publication_types:
- paper-conference
publication: '*Findings of the Association for Computational Linguistics: EMNLP 2024*'
doi: 10.18653/v1/2024.findings-emnlp.296
abstract: Human feedback is essential for building human-centered AI systems across
  domains where disagreement is prevalent, such as AI safety, content moderation,
  or sentiment analysis. Many disagreements, particularly in politically charged settings,
  arise because raters have opposing values or beliefs. Vicarious annotation is a
  method for breaking down disagreement by asking raters how they think others would
  annotate the data. In this paper, we explore the use of vicarious annotation with
  analytical methods for moderating rater disagreement. We employ rater cohesion metrics
  to study the potential influence of political affiliations and demographic backgrounds
  on raters' perceptions of offense. Additionally, we utilize CrowdTruth`s rater quality
  metrics, which consider the demographics of the raters, to score the raters and
  their annotations. We study how the rater quality metrics influence the in-group
  and cross-group rater cohesion across the personal and vicarious levels.
links:
- name: URL
  url: https://aclanthology.org/2024.findings-emnlp.296/
---
